{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "## Descripción\n",
    "Con este notebook de Python se muestra como utilizar la librería de [gensim](https://radimrehurek.com/gensim/index.html) para realizar sistemas de recuperación de información eficientes. En partícular, se muestra como cargar y procesar corpus de texto, así como utilizar representaciones vectoriales del corpus para realizar consultas basadas en similitud.\n",
    "\n",
    "**Los objetivos de aprendizaje son**:\n",
    "\n",
    "1. Cargar de manera eficiente datasets de texto con **gensim**.\n",
    "2. Aplicar técnicas de procesamiento de texto al corpus con **gensim**.\n",
    "3. Generar representaciones vectoriales del corpus con **gensim**.\n",
    "4. Constuir sistemas de recuperación de información con **gensim**.\n",
    "\n",
    "## Metodología\n",
    "Este notebook será un tutorial para aprender a instalar y usar **gensim** con el fin de crear sistemas de recuperación de información robustos y eficientes. Adicionalmente, se referirá al estudiante a la documentación de la librería y de los métodos vistos para que pueda ampliar la información sobre su uso.\n",
    "\n",
    "La estructura del notebook es la siguiente:\n",
    "* [1. Corpus](#corpus)\n",
    "    * [1.1 Cargar un corpus con streaming de datos para uso eficiente de la memoria](#corpus-load_data)\n",
    "* [2. Procesamiento de texto](#2-procesamiento-de-texto)\n",
    "    * [2.1. Otras técnicas de procesamiento de texto](#21-otras-técnicas-de-procesamiento-de-texto)\n",
    "* [3. Construir el vocabulario](#3-construir-el-vocabulario)\n",
    "* [4. Representaciones vectoriales](#4-representaciones-vectoriales)\n",
    "    * [4.1. Representación de bolsa de palabras](#41-representación-de-bolsa-de-palabras)\n",
    "    * [4.2. Representación de bolsa de palabras con puntajes **tf-idf**](#42-representación-de-bolsa-de-palabras-con-puntajes-tf-idf)\n",
    "    * [4.3. Guardar los modelos entrenados y el corpus transformado](#43-guardar-los-modelos-entrenados-y-el-corpus-transformado)\n",
    "    * [4.4. Compatibilidad con **numpy** y **scipy**](#44-compatibilidad-con-numpy-y-scipy)\n",
    "* [5. Construcción de sistemas de recuperación](#5-construcción-de-sistemas-de-recuperación)\n",
    "* [6. Conclusiones](#6-conclusiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalación de la librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para instalar localmente, descomente la siguiente línea\n",
    "# pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Corpus <a class=\"anchor\" id=\"corpus\"></a>\n",
    "\n",
    "Para **gensim** un corpus es simplemente una colección de documentos, en donde cada documento es un string de Python con el contenido textual del documento.\n",
    "\n",
    "A continuación vemos el ejemplo de un corpus, que será el punto de partida para desarollar nuestro sistema de recuperación de información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cargar un corpus con streaming de datos para uso eficiente de la memoria <a class=\"anchor\" id=\"corpus-load_data\"></a>\n",
    "\n",
    "Note que el corpus anterior reside completamente en la memoria RAM debido a que es una lista de Python. Para dataset reales, que normalmente suelen tener tamaños del orden de GBs no sería conveniente tener todo el dataset almacenado en nuestra RAM. Por esta razón, **gensim** acepta como corpus cualquier objeto iterable.\n",
    "\n",
    "Este diseño de **gensim** nos permite en conjunto con librarías como [smart_open](https://pypi.org/project/smart-open/) (ya viene incluida con Python 3) cargar nuestro dataset sin almacenarlo directamente en RAM, sino cargar únicamente los documentos en el momento que se necesitan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human machine interface for lab abc computer applications\n",
      "\n",
      "A survey of user opinion of computer system response time\n",
      "\n",
      "The EPS user interface management system\n",
      "\n",
      "System and human system engineering testing of EPS\n",
      "\n",
      "Relation of user perceived response time to error measurement\n",
      "\n",
      "The generation of random binary unordered trees\n",
      "\n",
      "The intersection graph of paths in trees\n",
      "\n",
      "Graph minors IV Widths of trees and well quasi ordering\n",
      "\n",
      "Graph minors A survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from smart_open import open\n",
    "\n",
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        for line in open('https://radimrehurek.com/mycorpus.txt'):\n",
    "            yield line\n",
    "\n",
    "corpus = MyCorpus()\n",
    "for doc in corpus:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Procesamiento de texto <a class=\"anchor\" id=\"text_processing\" name=\"text_processing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En **gensim** unsa de las formas más simples de procesar y tokenizar el texto, es a través de la función de utilidad [simple_process](https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess). Esta función se encarga de:\n",
    "\n",
    "* Convertir el texto a minúsculas.\n",
    "* Tokenizar el texto ignorando caracteres de puntuación.\n",
    "* Ignorar tokens muy cortos o muy largos.\n",
    "* Remover los acentos de los tokens (opcional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human',\n",
      " 'machine',\n",
      " 'interface',\n",
      " 'for',\n",
      " 'lab',\n",
      " 'abc',\n",
      " 'computer',\n",
      " 'applications']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Tokenizar los documentos\n",
    "tokenized_docs = [simple_preprocess(doc) for doc in corpus]\n",
    "\n",
    "# Imprimir el primer documento tokenizado\n",
    "pprint.pprint(tokenized_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto **simple_preprocess** elimina tokens con menos de 2 caracteres o más de 15 caracteres. Además, de manera opcional se pueden remover los acentos del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'sample', 'text', 'estas']\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"This, is a sample text. largewoooooooord, estás\"\n",
    "print(simple_preprocess(sample_text, deacc=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Otras técnicas de procesamiento de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función **preprocess_string** de **gensim** nos permite aplicar distintas técnicas de procesamiento de texto de manera fácil.\n",
    "Esta función recibe una lista de funciones de procesamiento que se aplican al texto de entrada.\n",
    "\n",
    "Por defecto esta función aplica la sigueinte lista de filtros:\n",
    "* `strip_tags()`: Elimina tags tipo HTML.\n",
    "* `strip_punctuation()`: Elimina caracteres de puntuación como comas y puntos.\n",
    "* `strip_multiple_whitespaces()`: Elimina multiples caracteres de espacios entre palabras.\n",
    "* `strip_numeric()`: Elimina los dígitos del texto.\n",
    "* `remove_stopwords()`: Elimina un listado de palabras de parada en inglés.\n",
    "* `strip_short()`: Elimina palabras con menos de 3 caracteres.\n",
    "* `stem_text()`: Aplicar stemming al texto. Solo funciona para inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'world', 'appl', 'weather', 'good', 'todai', 'isn']\n",
      "['i', 'hello9', 'i', 'b', 'wo4rld', 'b', 'apples', 'the', 'weather', 'is', 'is', 'really', 'good', 'today', 'isn', 't', 'it']\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "\n",
    "sample_text = \"<i>Hello9</i> <b>Wo4rld</b> apples! The     weather_is  is really good today, isn't it?\"\n",
    "\n",
    "# Aplicar el preprocesamiento por defecto\n",
    "print(preprocess_string(sample_text))\n",
    "\n",
    "# Aplicar el preprocesamiento con filtros personalizados\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), strip_punctuation]\n",
    "print(preprocess_string(sample_text, CUSTOM_FILTERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, se recomienda que el procesamiento de texto se realice \"on the fly\" al momento de cargar cada uno de los documentos. De esta manera, se evita cargar todo el dataset en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'machin', 'interfac', 'lab', 'abc', 'applic']\n",
      "['survei', 'user', 'opinion', 'respons', 'time']\n",
      "['ep', 'user', 'interfac', 'manag']\n",
      "['human', 'engin', 'test', 'ep']\n",
      "['relat', 'user', 'perceiv', 'respons', 'time', 'error', 'measur']\n",
      "['gener', 'random', 'binari', 'unord', 'tree']\n",
      "['intersect', 'graph', 'path', 'tree']\n",
      "['graph', 'minor', 'width', 'tree', 'quasi', 'order']\n",
      "['graph', 'minor', 'survei']\n"
     ]
    }
   ],
   "source": [
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        for line in open('https://radimrehurek.com/mycorpus.txt'):\n",
    "            # Realizar el procesamiento del texto y la tokenización aquí\n",
    "            yield preprocess_string(line)\n",
    "\n",
    "corpus = MyCorpus()\n",
    "for doc in corpus:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construir el vocabulario\n",
    "\n",
    "La clase `corpora.Dictionary` de **gensim** nos permite construir el vocabulario a partir de los documentos del corpus, y adicionalmente asigna un ID a cada palabra del vocabulario, lo que facilita la construcción de las representaciones vectoriales que generaremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<31 unique tokens: ['abc', 'applic', 'human', 'interfac', 'lab']...>\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos guardar y cargar el diccionario construido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('midict.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<31 unique tokens: ['abc', 'applic', 'human', 'interfac', 'lab']...>\n"
     ]
    }
   ],
   "source": [
    "corpora.Dictionary.load('midict.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver los ids asignados a cada token del vocabulario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc': 0,\n",
       " 'applic': 1,\n",
       " 'human': 2,\n",
       " 'interfac': 3,\n",
       " 'lab': 4,\n",
       " 'machin': 5,\n",
       " 'opinion': 6,\n",
       " 'respons': 7,\n",
       " 'survei': 8,\n",
       " 'time': 9,\n",
       " 'user': 10,\n",
       " 'ep': 11,\n",
       " 'manag': 12,\n",
       " 'engin': 13,\n",
       " 'test': 14,\n",
       " 'error': 15,\n",
       " 'measur': 16,\n",
       " 'perceiv': 17,\n",
       " 'relat': 18,\n",
       " 'binari': 19,\n",
       " 'gener': 20,\n",
       " 'random': 21,\n",
       " 'tree': 22,\n",
       " 'unord': 23,\n",
       " 'graph': 24,\n",
       " 'intersect': 25,\n",
       " 'path': 26,\n",
       " 'minor': 27,\n",
       " 'order': 28,\n",
       " 'quasi': 29,\n",
       " 'width': 30}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Representaciones vectoriales\n",
    "\n",
    "Como lo vimos en talleres anteriores, las representaciones vectoriales son útiles para crear sistemas de recuperación de información.\n",
    "**gensim** nos permite crear representaciones de bolsa de palabras, entre otras. Además, nos permite transformar representaciones de texto en otro tipo de representaciones. Por ejemplo, podemos construir una representación de bolsa de palabras con las frecuencias, y luego podemos transformar esta representación a los puntajes **tf-idf**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Representacón de bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La representación vectorial generada por **gensim** consiste en tuplas, en donde el primer valor indica el id de la palabra del vocabulario, y el segundo valor representa la frecuencia de ese token en el documento.\n",
    "\n",
    "Esta representación hace un uso eficiente de la memoria, ya que solo se generan las tuplas para los tokens con una frecuencia mayor a 0 en el documento.\n",
    "\n",
    "**gensim** permite el uso the cualquier iterador que retorne un vector por documento a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]\n",
      "[(6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]\n",
      "[(3, 1), (10, 1), (11, 1), (12, 1)]\n",
      "[(2, 1), (11, 1), (13, 1), (14, 1)]\n",
      "[(7, 1), (9, 1), (10, 1), (15, 1), (16, 1), (17, 1), (18, 1)]\n",
      "[(19, 1), (20, 1), (21, 1), (22, 1), (23, 1)]\n",
      "[(22, 1), (24, 1), (25, 1), (26, 1)]\n",
      "[(22, 1), (24, 1), (27, 1), (28, 1), (29, 1), (30, 1)]\n",
      "[(8, 1), (24, 1), (27, 1)]\n"
     ]
    }
   ],
   "source": [
    "class Bow_Corpus:\n",
    "    def __iter__(self):\n",
    "        for doc in corpus:\n",
    "            # Vectorización del texto por documento\n",
    "            yield dictionary.doc2bow(doc)\n",
    "\n",
    "bow_corpus = Bow_Corpus()\n",
    "for doc in bow_corpus:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Representación de bolsa de palabras con puntajes **tf-idf**\n",
    "\n",
    "En **gensim** podemos usar la representación de bolsa de palabras básica para generar representaciones más avanzadas, usando los puntajes **tf-idf** en vez de la frecuencia por token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4500498962785324), (1, 0.4500498962785324), (2, 0.3080749612015952), (3, 0.3080749612015952), (4, 0.4500498962785324), (5, 0.4500498962785324)]\n",
      "[(6, 0.6136280137156085), (7, 0.42004992797654267), (8, 0.42004992797654267), (9, 0.42004992797654267), (10, 0.30681400685780424)]\n",
      "[(3, 0.4628644263314176), (10, 0.3380866887867002), (11, 0.4628644263314176), (12, 0.6761733775734003)]\n",
      "[(2, 0.39942082240973076), (11, 0.39942082240973076), (13, 0.5834920793168784), (14, 0.5834920793168784)]\n",
      "[(7, 0.30055933182961736), (9, 0.30055933182961736), (10, 0.21953536176370683), (15, 0.43907072352741366), (16, 0.43907072352741366), (17, 0.43907072352741366), (18, 0.43907072352741366)]\n",
      "[(19, 0.48507125007266594), (20, 0.48507125007266594), (21, 0.48507125007266594), (22, 0.24253562503633297), (23, 0.48507125007266594)]\n",
      "[(22, 0.31622776601683794), (24, 0.31622776601683794), (25, 0.6324555320336759), (26, 0.6324555320336759)]\n",
      "[(22, 0.25098743403237606), (24, 0.25098743403237606), (27, 0.3436194281611727), (28, 0.5019748680647521), (29, 0.5019748680647521), (30, 0.5019748680647521)]\n",
      "[(8, 0.6282580468670046), (24, 0.45889394536615247), (27, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "# Entrenamiento del modelo TF-IDF\n",
    "tfidf = models.TfidfModel(bow_corpus, normalize=True) # normalize=True normaliza los valores en el rango [0, 1]\n",
    "\n",
    "# Aplicar el modelo TF-IDF al corpus\n",
    "tfidf_corpus = tfidf[bow_corpus]\n",
    "\n",
    "# Imnprimer los vectores TF-IDF\n",
    "for doc in tfidf_corpus:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamar a `tfidf[bow_corpus]` genera un \"wrapper\" sobre el objeto del corpus. Por lo tanto, la real transformación vectorial se realizar por cada documento al momento de iterar spbre el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Guardar los modelos entrenados y el corpus transformado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos guardar y cargar el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.save('simple_corpus.tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = models.TfidfModel.load('simple_corpus.tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gensim** tiene diferentes transformaciones disponibles. Puede ver una breve descripción de cada una [aquí](https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html#available-transformations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, puede guardar y cargar el corpus transformado en distintos formatos. Uno de los más populares es el formato [Market Matrix](http://math.nist.gov/MatrixMarket/formats.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('/tmp/corpus.mm', tfidf_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_corpus = corpora.MmCorpus('/tmp/corpus.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4500498962785324), (1, 0.4500498962785324), (2, 0.3080749612015952), (3, 0.3080749612015952), (4, 0.4500498962785324), (5, 0.4500498962785324)]\n",
      "[(6, 0.6136280137156085), (7, 0.42004992797654267), (8, 0.42004992797654267), (9, 0.42004992797654267), (10, 0.30681400685780424)]\n",
      "[(3, 0.4628644263314176), (10, 0.3380866887867002), (11, 0.4628644263314176), (12, 0.6761733775734003)]\n",
      "[(2, 0.39942082240973076), (11, 0.39942082240973076), (13, 0.5834920793168784), (14, 0.5834920793168784)]\n",
      "[(7, 0.30055933182961736), (9, 0.30055933182961736), (10, 0.21953536176370683), (15, 0.43907072352741366), (16, 0.43907072352741366), (17, 0.43907072352741366), (18, 0.43907072352741366)]\n",
      "[(19, 0.48507125007266594), (20, 0.48507125007266594), (21, 0.48507125007266594), (22, 0.24253562503633297), (23, 0.48507125007266594)]\n",
      "[(22, 0.31622776601683794), (24, 0.31622776601683794), (25, 0.6324555320336759), (26, 0.6324555320336759)]\n",
      "[(22, 0.25098743403237606), (24, 0.25098743403237606), (27, 0.3436194281611727), (28, 0.5019748680647521), (29, 0.5019748680647521), (30, 0.5019748680647521)]\n",
      "[(8, 0.6282580468670046), (24, 0.45889394536615247), (27, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "for d in tfidf_corpus:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Compatibilidad con **numpy** y **Scipy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo desea, las representaciones vectoriales de **gensim** pueden ser transformadas a areglos de **numpy**.\n",
    "\n",
    "Recuerde que los arreglos de **numpy** son densos. Es decir, que todas sus dimensiones se representan con un valor así la mayoría de dimensiones tengan valor 0. Por lo tanto, no se recomienda esta transformación para datasets grandes ya que puede causar desbordamiento de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "# Convertir un corpus de Gensim a una matriz densa de Numpy\n",
    "numpy_matrix = gensim.matutils.corpus2dense(tfidf_corpus, num_terms=len(dictionary))\n",
    "\n",
    "# Convertir una matriz densa de Numpy a un corpus de Gensim\n",
    "new_corpus = gensim.matutils.Dense2Corpus(numpy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde numpy [(0, 0.45004990696907043), (1, 0.45004990696907043), (2, 0.308074951171875), (3, 0.308074951171875), (4, 0.45004990696907043), (5, 0.45004990696907043)]\n",
      "Doc original [(0, 0.4500498962785324), (1, 0.4500498962785324), (2, 0.3080749612015952), (3, 0.3080749612015952), (4, 0.4500498962785324), (5, 0.4500498962785324)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde numpy [(6, 0.6136280298233032), (7, 0.4200499355792999), (8, 0.4200499355792999), (9, 0.4200499355792999), (10, 0.3068140149116516)]\n",
      "Doc original [(6, 0.6136280137156085), (7, 0.42004992797654267), (8, 0.42004992797654267), (9, 0.42004992797654267), (10, 0.30681400685780424)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde numpy [(3, 0.4628644287586212), (10, 0.33808669447898865), (11, 0.4628644287586212), (12, 0.6761733889579773)]\n",
      "Doc original [(3, 0.4628644263314176), (10, 0.3380866887867002), (11, 0.4628644263314176), (12, 0.6761733775734003)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde numpy [(2, 0.399420827627182), (11, 0.399420827627182), (13, 0.5834921002388), (14, 0.5834921002388)]\n",
      "Doc original [(2, 0.39942082240973076), (11, 0.39942082240973076), (13, 0.5834920793168784), (14, 0.5834920793168784)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde numpy [(7, 0.3005593419075012), (9, 0.3005593419075012), (10, 0.21953536570072174), (15, 0.4390707314014435), (16, 0.4390707314014435), (17, 0.4390707314014435), (18, 0.4390707314014435)]\n",
      "Doc original [(7, 0.30055933182961736), (9, 0.30055933182961736), (10, 0.21953536176370683), (15, 0.43907072352741366), (16, 0.43907072352741366), (17, 0.43907072352741366), (18, 0.43907072352741366)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde numpy [(19, 0.48507124185562134), (20, 0.48507124185562134), (21, 0.48507124185562134), (22, 0.24253562092781067), (23, 0.48507124185562134)]\n",
      "Doc original [(19, 0.48507125007266594), (20, 0.48507125007266594), (21, 0.48507125007266594), (22, 0.24253562503633297), (23, 0.48507125007266594)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde numpy [(22, 0.3162277638912201), (24, 0.3162277638912201), (25, 0.6324555277824402), (26, 0.6324555277824402)]\n",
      "Doc original [(22, 0.31622776601683794), (24, 0.31622776601683794), (25, 0.6324555320336759), (26, 0.6324555320336759)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde numpy [(22, 0.2509874403476715), (24, 0.2509874403476715), (27, 0.3436194360256195), (28, 0.501974880695343), (29, 0.501974880695343), (30, 0.501974880695343)]\n",
      "Doc original [(22, 0.25098743403237606), (24, 0.25098743403237606), (27, 0.3436194281611727), (28, 0.5019748680647521), (29, 0.5019748680647521), (30, 0.5019748680647521)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde numpy [(8, 0.6282580494880676), (24, 0.45889395475387573), (27, 0.6282580494880676)]\n",
      "Doc original [(8, 0.6282580468670046), (24, 0.45889394536615247), (27, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "for doc1, doc2 in zip(new_corpus, tfidf_corpus):\n",
    "    print(\"Son iguales las dos representaciones vectoriales:\", np.allclose(doc1, doc2))\n",
    "    print(\"Doc desde numpy\", doc1)\n",
    "    print(\"Doc original\", doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se pueden realizar conversiones entre matrices `scipy.sparse` y **gensim**. Las representaciones `scipy.sparse` también son representaciones dispersas que son eficientes en memoria, estos objetos son usados por librerías como **scikit-learn** como salida de `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir un corpus de Gensim a una matriz dispersa de Scipy\n",
    "scipy_matrix = gensim.matutils.corpus2csc(tfidf_corpus)\n",
    "\n",
    "# Convertir una matriz dispersa de Scipy a un corpus de Gensim\n",
    "new_corpus = gensim.matutils.Sparse2Corpus(scipy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde scipy [(0, 0.4500498962785324), (1, 0.4500498962785324), (2, 0.3080749612015952), (3, 0.3080749612015952), (4, 0.4500498962785324), (5, 0.4500498962785324)]\n",
      "Doc original [(0, 0.4500498962785324), (1, 0.4500498962785324), (2, 0.3080749612015952), (3, 0.3080749612015952), (4, 0.4500498962785324), (5, 0.4500498962785324)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde scipy [(6, 0.6136280137156085), (7, 0.42004992797654267), (8, 0.42004992797654267), (9, 0.42004992797654267), (10, 0.30681400685780424)]\n",
      "Doc original [(6, 0.6136280137156085), (7, 0.42004992797654267), (8, 0.42004992797654267), (9, 0.42004992797654267), (10, 0.30681400685780424)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde scipy [(3, 0.4628644263314176), (10, 0.3380866887867002), (11, 0.4628644263314176), (12, 0.6761733775734003)]\n",
      "Doc original [(3, 0.4628644263314176), (10, 0.3380866887867002), (11, 0.4628644263314176), (12, 0.6761733775734003)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde scipy [(2, 0.39942082240973076), (11, 0.39942082240973076), (13, 0.5834920793168784), (14, 0.5834920793168784)]\n",
      "Doc original [(2, 0.39942082240973076), (11, 0.39942082240973076), (13, 0.5834920793168784), (14, 0.5834920793168784)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde scipy [(7, 0.30055933182961736), (9, 0.30055933182961736), (10, 0.21953536176370683), (15, 0.43907072352741366), (16, 0.43907072352741366), (17, 0.43907072352741366), (18, 0.43907072352741366)]\n",
      "Doc original [(7, 0.30055933182961736), (9, 0.30055933182961736), (10, 0.21953536176370683), (15, 0.43907072352741366), (16, 0.43907072352741366), (17, 0.43907072352741366), (18, 0.43907072352741366)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde scipy [(19, 0.48507125007266594), (20, 0.48507125007266594), (21, 0.48507125007266594), (22, 0.24253562503633297), (23, 0.48507125007266594)]\n",
      "Doc original [(19, 0.48507125007266594), (20, 0.48507125007266594), (21, 0.48507125007266594), (22, 0.24253562503633297), (23, 0.48507125007266594)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde scipy [(22, 0.31622776601683794), (24, 0.31622776601683794), (25, 0.6324555320336759), (26, 0.6324555320336759)]\n",
      "Doc original [(22, 0.31622776601683794), (24, 0.31622776601683794), (25, 0.6324555320336759), (26, 0.6324555320336759)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde scipy [(22, 0.25098743403237606), (24, 0.25098743403237606), (27, 0.3436194281611727), (28, 0.5019748680647521), (29, 0.5019748680647521), (30, 0.5019748680647521)]\n",
      "Doc original [(22, 0.25098743403237606), (24, 0.25098743403237606), (27, 0.3436194281611727), (28, 0.5019748680647521), (29, 0.5019748680647521), (30, 0.5019748680647521)]\n",
      "Son iguales las dos representaciones vectoriales: True\n",
      "Doc desde scipy [(8, 0.6282580468670046), (24, 0.45889394536615247), (27, 0.6282580468670046)]\n",
      "Doc original [(8, 0.6282580468670046), (24, 0.45889394536615247), (27, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "for doc1, doc2 in zip(new_corpus, tfidf_corpus):\n",
    "    print(\"Son iguales las dos representaciones vectoriales:\", np.allclose(doc1, doc2))\n",
    "    print(\"Doc desde scipy\", doc1)\n",
    "    print(\"Doc original\", doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Construcción de sistemas de recuperación\n",
    "\n",
    "Una vez se tiene la representación vectorial de corpus definida, el corpus se puede indexar para prepararlo para realizar consultas de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(tfidf_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este index generado también puede guardarse y cargarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.save('simple_corpus.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity.load('simple_corpus.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos realizar consultas a nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17402118 0.         0.         0.7071068  0.         0.\n",
      " 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Consulta a realizar\n",
    "query = 'humans complexity, engineering'\n",
    "\n",
    "# Aplicar el mismo preprocesamiento que se aplicó al corpus\n",
    "query_document = preprocess_string(query)\n",
    "\n",
    "# Utilizar la misma representación vectorial que se utilizó en el corpus\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "\n",
    "# Calcular la similitud de la consulta con los documentos del corpus\n",
    "sims = index[tfidf[query_bow]]\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenar los documentos según su puntaje de similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.7071068\n",
      "0 0.17402118\n",
      "1 0.0\n",
      "2 0.0\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.0\n",
      "7 0.0\n",
      "8 0.0\n"
     ]
    }
   ],
   "source": [
    "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "    print(document_number, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusiones\n",
    "\n",
    "Librerías como **gensim** nos permiten crear sistemas de recuperación de información de una manera rápida y eficiente. Estas librerías cobran especial importancia cuando los datasets son muy grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
